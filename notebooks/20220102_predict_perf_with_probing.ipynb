{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict performances with probing\n",
    "Task 1: Does probing results predict the GLUE task performances?  \n",
    "Task 2: Does probing results predict the robustness against generalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "import numpy as np\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>layer</th>\n",
       "      <th>task</th>\n",
       "      <th>config</th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>rs</th>\n",
       "      <th>train_size_per_class</th>\n",
       "      <th>nclasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0</td>\n",
       "      <td>bigram_shift</td>\n",
       "      <td>Full</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6560.2</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0</td>\n",
       "      <td>coordination_inversion</td>\n",
       "      <td>Full</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6560.2</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0</td>\n",
       "      <td>obj_number</td>\n",
       "      <td>Full</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6560.2</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0</td>\n",
       "      <td>odd_man_out</td>\n",
       "      <td>Full</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.500833</td>\n",
       "      <td>0.693146</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693149</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693149</td>\n",
       "      <td>6560.2</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0</td>\n",
       "      <td>past_present</td>\n",
       "      <td>Full</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>6560.2</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         LM  layer                    task config  \\\n",
       "0   embeddings_roberta_base      0            bigram_shift   Full   \n",
       "3   embeddings_roberta_base      0  coordination_inversion   Full   \n",
       "6   embeddings_roberta_base      0              obj_number   Full   \n",
       "9   embeddings_roberta_base      0             odd_man_out   Full   \n",
       "12  embeddings_roberta_base      0            past_present   Full   \n",
       "\n",
       "           model  train_acc  train_loss  val_acc  val_loss  test_acc  \\\n",
       "0   DecisionTree   0.500000    0.693147      0.5  0.693147       0.5   \n",
       "3   DecisionTree   0.500000    0.693147      0.5  0.693147       0.5   \n",
       "6   DecisionTree   0.500000    0.693147      0.5  0.693147       0.5   \n",
       "9   DecisionTree   0.500833    0.693146      0.5  0.693149       0.5   \n",
       "12  DecisionTree   0.500000    0.693147      0.5  0.693147       0.5   \n",
       "\n",
       "    test_loss      rs  train_size_per_class  nclasses  \n",
       "0    0.693147  6560.2                1200.0       2.0  \n",
       "3    0.693147  6560.2                1200.0       2.0  \n",
       "6    0.693147  6560.2                1200.0       2.0  \n",
       "9    0.693149  6560.2                1200.0       2.0  \n",
       "12   0.693147  6560.2                1200.0       2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probing_df = pd.read_csv(\"../reports/probing_roberta_base.csv\")\n",
    "probing_df = probing_df[probing_df[\"config\"]==\"Full\"]\n",
    "print(probing_df.shape)\n",
    "probing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probing_df[probing_df.LM==\"embeddings_roberta_base\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>LM</th>\n",
       "      <th>init_lr</th>\n",
       "      <th>slurm_id</th>\n",
       "      <th>dev_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rte</td>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5236891</td>\n",
       "      <td>0.7726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rte</td>\n",
       "      <td>embeddings_roberta_base_corr_500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5215525</td>\n",
       "      <td>0.7148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rte</td>\n",
       "      <td>embeddings_roberta_base_corr_1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5258357</td>\n",
       "      <td>0.7040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rte</td>\n",
       "      <td>embeddings_roberta_base_corr_2000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5258397</td>\n",
       "      <td>0.6859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rte</td>\n",
       "      <td>embeddings_roberta_base_corr_4000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5258437</td>\n",
       "      <td>0.5848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  task                                 LM  init_lr  slurm_id  dev_acc\n",
       "0  rte            embeddings_roberta_base  0.00001   5236891   0.7726\n",
       "1  rte   embeddings_roberta_base_corr_500  0.00001   5215525   0.7148\n",
       "2  rte  embeddings_roberta_base_corr_1000  0.00001   5258357   0.7040\n",
       "3  rte  embeddings_roberta_base_corr_2000  0.00001   5258397   0.6859\n",
       "4  rte  embeddings_roberta_base_corr_4000  0.00001   5258437   0.5848"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_df = pd.read_csv(\"../reports/glue_classification_results.csv\")\n",
    "glue_df = glue_df[~glue_df.task.str.contains(\"processed\")]\n",
    "print(glue_df.shape)\n",
    "glue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>init_lr</th>\n",
       "      <th>slurm_id</th>\n",
       "      <th>dev_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cola</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnli</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LM  init_lr  slurm_id  dev_acc\n",
       "task                                \n",
       "cola   6        6         6        6\n",
       "mrpc   6        6         6        6\n",
       "qnli   6        6         6        6\n",
       "qqp    6        6         6        6\n",
       "rte    6        6         6        6\n",
       "sst2   6        6         6        6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_df.groupby(\"task\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>rte</th>\n",
       "      <th>cola</th>\n",
       "      <th>qnli</th>\n",
       "      <th>mrpc</th>\n",
       "      <th>sst2</th>\n",
       "      <th>qqp</th>\n",
       "      <th>bigram_shift_layer_0</th>\n",
       "      <th>coordination_inversion_layer_0</th>\n",
       "      <th>obj_number_layer_0</th>\n",
       "      <th>...</th>\n",
       "      <th>past_present_layer_11</th>\n",
       "      <th>subj_number_layer_11</th>\n",
       "      <th>tree_depth_layer_11</th>\n",
       "      <th>bigram_shift_layer_12</th>\n",
       "      <th>coordination_inversion_layer_12</th>\n",
       "      <th>obj_number_layer_12</th>\n",
       "      <th>odd_man_out_layer_12</th>\n",
       "      <th>past_present_layer_12</th>\n",
       "      <th>subj_number_layer_12</th>\n",
       "      <th>tree_depth_layer_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857333</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.283714</td>\n",
       "      <td>0.850667</td>\n",
       "      <td>0.654333</td>\n",
       "      <td>0.787333</td>\n",
       "      <td>0.619667</td>\n",
       "      <td>0.879667</td>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.295238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings_roberta_base_corr_500</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.250381</td>\n",
       "      <td>0.685667</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.294857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings_roberta_base_corr_1000</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>0.721333</td>\n",
       "      <td>0.259905</td>\n",
       "      <td>0.605667</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.297714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings_roberta_base_corr_2000</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.747667</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.560667</td>\n",
       "      <td>0.870333</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.301143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embeddings_roberta_base_corr_4000</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.559333</td>\n",
       "      <td>0.540667</td>\n",
       "      <td>0.804333</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.810333</td>\n",
       "      <td>0.302667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embeddings_roberta_base_corr_6000</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867667</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.287619</td>\n",
       "      <td>0.552333</td>\n",
       "      <td>0.535667</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.571333</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.297810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  LM     rte    cola    qnli    mrpc    sst2  \\\n",
       "0            embeddings_roberta_base  0.7726  0.8437  0.9251  0.8995  0.9438   \n",
       "1   embeddings_roberta_base_corr_500  0.7148  0.8322  0.9213  0.8750  0.9415   \n",
       "2  embeddings_roberta_base_corr_1000  0.7040  0.8380  0.9213  0.8824  0.9392   \n",
       "3  embeddings_roberta_base_corr_2000  0.6859  0.8341  0.9185  0.8824  0.9415   \n",
       "4  embeddings_roberta_base_corr_4000  0.5848  0.8399  0.9209  0.8873  0.9450   \n",
       "5  embeddings_roberta_base_corr_6000  0.6679  0.8293  0.9229  0.8554  0.9392   \n",
       "\n",
       "      qqp  bigram_shift_layer_0  coordination_inversion_layer_0  \\\n",
       "0  0.9143                   0.5                             0.5   \n",
       "1  0.9164                   0.5                             0.5   \n",
       "2  0.9160                   0.5                             0.5   \n",
       "3  0.9166                   0.5                             0.5   \n",
       "4  0.9165                   0.5                             0.5   \n",
       "5  0.9169                   0.5                             0.5   \n",
       "\n",
       "   obj_number_layer_0  ...  past_present_layer_11  subj_number_layer_11  \\\n",
       "0                 0.5  ...               0.857333              0.793333   \n",
       "1                 0.5  ...               0.865333              0.704333   \n",
       "2                 0.5  ...               0.819000              0.721333   \n",
       "3                 0.5  ...               0.864333              0.747667   \n",
       "4                 0.5  ...               0.864333              0.785667   \n",
       "5                 0.5  ...               0.867667              0.803333   \n",
       "\n",
       "   tree_depth_layer_11  bigram_shift_layer_12  \\\n",
       "0             0.283714               0.850667   \n",
       "1             0.250381               0.685667   \n",
       "2             0.259905               0.605667   \n",
       "3             0.276190               0.579000   \n",
       "4             0.284190               0.559333   \n",
       "5             0.287619               0.552333   \n",
       "\n",
       "   coordination_inversion_layer_12  obj_number_layer_12  odd_man_out_layer_12  \\\n",
       "0                         0.654333             0.787333              0.619667   \n",
       "1                         0.546667             0.813000              0.582667   \n",
       "2                         0.547000             0.810000              0.564333   \n",
       "3                         0.539333             0.810000              0.560667   \n",
       "4                         0.540667             0.804333              0.570667   \n",
       "5                         0.535667             0.813333              0.571333   \n",
       "\n",
       "   past_present_layer_12  subj_number_layer_12  tree_depth_layer_12  \n",
       "0               0.879667              0.815333             0.295238  \n",
       "1               0.868000              0.806000             0.294857  \n",
       "2               0.864333              0.814667             0.297714  \n",
       "3               0.870333              0.812000             0.301143  \n",
       "4               0.865333              0.810333             0.302667  \n",
       "5               0.865333              0.810000             0.297810  \n",
       "\n",
       "[6 rows x 98 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile a dataframe for linear regression\n",
    "def prepare_data(probing_df, glue_df):\n",
    "\n",
    "    lms = glue_df[\"LM\"].drop_duplicates().tolist()\n",
    "    result_df = {\"LM\": lms}\n",
    "    for lm in lms:\n",
    "        # Classification\n",
    "        # Each task: one LM (one row in glue_df) as target. \n",
    "        df = glue_df[glue_df.LM==lm]  # 6 rows\n",
    "        for i, row in df.iterrows():\n",
    "            if row.task not in result_df:\n",
    "                result_df[row.task] = [row.dev_acc]\n",
    "            else:\n",
    "                result_df[row.task].append(row.dev_acc)\n",
    "\n",
    "        # Probing\n",
    "        # 13 layers x 7 tasks = 91 (rows) as data from probing_df as features.\n",
    "        df = probing_df[probing_df.LM==lm]  # 91 rows  \n",
    "        for i, row in df.iterrows():\n",
    "            featname = \"{}_layer_{}\".format(row.task, row.layer)\n",
    "            featval = row.test_acc \n",
    "            if featname in result_df:\n",
    "                result_df[featname].append(featval)\n",
    "            else:\n",
    "                result_df[featname] = [featval]\n",
    "    \n",
    "    return pd.DataFrame(result_df)\n",
    "\n",
    "linreg_data = prepare_data(probing_df, glue_df)\n",
    "linreg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_data.to_csv(\"../reports/task1_predict_task_performance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zining/anaconda3/envs/pytorch12/lib/python3.7/site-packages/statsmodels/stats/stattools.py:75: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n",
      "/home/zining/anaconda3/envs/pytorch12/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:1728: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/home/zining/anaconda3/envs/pytorch12/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:1729: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  * (1 - self.rsquared))\n",
      "/home/zining/anaconda3/envs/pytorch12/lib/python3.7/site-packages/statsmodels/regression/linear_model.py:1650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>rte</td>       <th>  R-squared:         </th> <td>   1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 02 Jan 2022</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:54:47</td>     <th>  Log-Likelihood:    </th> <td>  195.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     6</td>      <th>  AIC:               </th> <td>  -380.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     0</td>      <th>  BIC:               </th> <td>  -381.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_0</th>  <td>    0.2830</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_1</th>  <td>    1.5417</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_2</th>  <td>   -1.5357</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_3</th>  <td>   -0.3854</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_4</th>  <td>    0.0662</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_5</th>  <td>    1.0785</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_6</th>  <td>   -0.1433</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_7</th>  <td>    0.5390</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_8</th>  <td>    0.9428</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_9</th>  <td>   -2.4892</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_10</th> <td>    0.3756</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_11</th> <td>    0.5082</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bigram_shift_layer_12</th> <td>    0.3744</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.004</td> <th>  Prob(JB):          </th> <td>   0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.950</td> <th>  Cond. No.          </th> <td>    267.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The input rank is higher than the number of observations."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    rte   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                    nan\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Sun, 02 Jan 2022   Prob (F-statistic):                nan\n",
       "Time:                        22:54:47   Log-Likelihood:                 195.98\n",
       "No. Observations:                   6   AIC:                            -380.0\n",
       "Df Residuals:                       0   BIC:                            -381.2\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "bigram_shift_layer_0      0.2830        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_1      1.5417        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_2     -1.5357        inf         -0        nan         nan         nan\n",
       "bigram_shift_layer_3     -0.3854        inf         -0        nan         nan         nan\n",
       "bigram_shift_layer_4      0.0662        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_5      1.0785        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_6     -0.1433        inf         -0        nan         nan         nan\n",
       "bigram_shift_layer_7      0.5390        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_8      0.9428        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_9     -2.4892        inf         -0        nan         nan         nan\n",
       "bigram_shift_layer_10     0.3756        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_11     0.5082        inf          0        nan         nan         nan\n",
       "bigram_shift_layer_12     0.3744        inf          0        nan         nan         nan\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                   0.023\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.008\n",
       "Skew:                          -1.004   Prob(JB):                        0.604\n",
       "Kurtosis:                       2.950   Cond. No.                         267.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The input rank is higher than the number of observations.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = linreg_data[\"rte\"]\n",
    "#X = linreg_data.drop(columns=[\"LM\", \"rte\", \"cola\", \"qnli\", \"mrpc\", \"sst2\", \"qqp\"])\n",
    "X = linreg_data[[f\"bigram_shift_layer_{i}\" for i in range(13)]]\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91113a6d945a23a1d7d4073c51114eab5e8effc568ceeb9bfdc399b075c747f0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('pytorch12': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
