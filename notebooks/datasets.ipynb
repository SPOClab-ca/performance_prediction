{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-coverage",
   "metadata": {},
   "source": [
    "# Huggingface datasets for GLUE\n",
    "\n",
    "For different tasks, how to get the train/val/test split from `datasets`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "failing-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets version: 1.12.1\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(\"datasets version:\", datasets.__version__)\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "tough-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/ax/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b442c0026834f70b4cb8e65953c4e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: ax\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 1104\n",
      "    })\n",
      "})\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ab9be7f7eb42c1ad9afa90cc0d6b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: cola\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 8551\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1043\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1063\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f768808719443584039d41eacae6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: mnli\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 392702\n",
      "    })\n",
      "    validation_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9815\n",
      "    })\n",
      "    validation_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9832\n",
      "    })\n",
      "    test_matched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9796\n",
      "    })\n",
      "    test_mismatched: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9847\n",
      "    })\n",
      "})\n",
      "train: [0 1 2]\n",
      "validation_matched: [0 1 2]\n",
      "validation_mismatched: [0 1 2]\n",
      "test_matched: [-1]\n",
      "test_mismatched: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/mnli_matched/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364dea7fed794182b611ad851ea2425a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: mnli_matched\n",
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9815\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9796\n",
      "    })\n",
      "})\n",
      "validation: [0 1 2]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/mnli_mismatched/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef64cf531194c4cbdeb6f7fce2d821d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: mnli_mismatched\n",
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9832\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
      "        num_rows: 9847\n",
      "    })\n",
      "})\n",
      "validation: [0 1 2]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cd14e5ef3d40b383c147c663b56e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: mrpc\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87771b2d51e14360ac9da3c8cd789683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: qnli\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 104743\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'sentence', 'label', 'idx'],\n",
      "        num_rows: 5463\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d9268bfe6c4a67976c054ca2ae7f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: qqp\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 363846\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 40430\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question1', 'question2', 'label', 'idx'],\n",
      "        num_rows: 390965\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dd874f0e7748f29c0fd58c43a643e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: rte\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 2490\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6987471300b54d5e89f34eb5ce185729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: sst2\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [-1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35df2fbc20434c408d33de06c532e0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: stsb\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 5749\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1379\n",
      "    })\n",
      "})\n",
      "train: [0.         0.067      0.118      0.14300001 0.17       0.2\n",
      " 0.23100001 0.25       0.333      0.40000001 0.417      0.5\n",
      " 0.60000002 0.64300001 0.667      0.727      0.75       0.80000001\n",
      " 0.833      0.85000002 0.889      0.89999998 0.94400001 1.\n",
      " 1.10000002 1.20000005 1.25       1.273      1.28600001 1.33299994\n",
      " 1.39999998 1.5        1.5333333  1.55599999 1.58299994 1.60000002\n",
      " 1.64300001 1.66700006 1.70000005 1.73300004 1.75       1.778\n",
      " 1.79999995 1.84599996 2.         2.11111116 2.20000005 2.25\n",
      " 2.32999992 2.33299994 2.375      2.4000001  2.4666667  2.5\n",
      " 2.53299999 2.58299994 2.58800006 2.5999999  2.625      2.64700007\n",
      " 2.66700006 2.70000005 2.75       2.76900005 2.79999995 2.81800008\n",
      " 2.82999992 2.875      2.90899992 2.91700006 3.         3.05599999\n",
      " 3.06699991 3.0999999  3.11100006 3.16700006 3.20000005 3.23099995\n",
      " 3.25       3.273      3.33299994 3.33333325 3.4000001  3.43799996\n",
      " 3.44400001 3.45499992 3.5        3.53299999 3.5999999  3.61500001\n",
      " 3.625      3.64299989 3.66700006 3.67000008 3.69199991 3.75\n",
      " 3.7650001  3.76900005 3.77777767 3.78600001 3.79999995 3.83299994\n",
      " 3.84599996 3.85700011 3.8670001  3.875      3.90899992 3.9230001\n",
      " 3.9289999  3.93300009 3.93799996 3.94099998 4.         4.05600023\n",
      " 4.09100008 4.0999999  4.1329999  4.17600012 4.19999981 4.25\n",
      " 4.30800009 4.32999992 4.33300018 4.36399984 4.4000001  4.5\n",
      " 4.5710001  4.57142878 4.5999999  4.66699982 4.72700024 4.75\n",
      " 4.77799988 4.80000019 4.81799984 4.85699987 4.875      4.90899992\n",
      " 4.92299986 5.        ]\n",
      "validation: [0.         0.083      0.1        0.2        0.25       0.40000001\n",
      " 0.5        0.60000002 0.63599998 0.67000002 0.75       0.778\n",
      " 0.80000001 0.833      1.         1.15400004 1.20000005 1.25\n",
      " 1.29999995 1.33299994 1.39999998 1.5        1.53299999 1.58299994\n",
      " 1.60000002 1.66700006 1.66999996 1.71399999 1.75       1.79999995\n",
      " 1.91700006 2.         2.16700006 2.20000005 2.25       2.33299994\n",
      " 2.33333325 2.375      2.4000001  2.5        2.5999999  2.61500001\n",
      " 2.69199991 2.75       2.79999995 2.81200004 3.         3.09100008\n",
      " 3.0999999  3.20000005 3.25       3.33299994 3.4000001  3.41700006\n",
      " 3.5        3.5999999  3.66700006 3.69199991 3.71399999 3.75\n",
      " 3.79999995 3.82399988 4.         4.11100006 4.19999981 4.21400023\n",
      " 4.25       4.33300018 4.4000001  4.4289999  4.5        4.5999999\n",
      " 4.66699982 4.75       4.80000019 4.85699987 4.90899992 5.        ]\n",
      "test: [-1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/wnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c66505fef34af78e22bdd32899c19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "task name: wnli\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 635\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 71\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 146\n",
      "    })\n",
      "})\n",
      "train: [0 1]\n",
      "validation: [0 1]\n",
      "test: [-1]\n"
     ]
    }
   ],
   "source": [
    "# GLUE datasets\n",
    "glue_item_names = [\"ax\", \"cola\", \"mnli\", \"mnli_matched\", \"mnli_mismatched\", \n",
    "         \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\",\n",
    "        \"stsb\", \"wnli\"]\n",
    "for name in glue_item_names:\n",
    "    ds = load_dataset(\"glue\", name)\n",
    "    print(\"task name:\", name)\n",
    "    print(ds)\n",
    "    for split in ds:\n",
    "        print(split, end=\": \")\n",
    "        print(np.unique(ds[split][\"label\"]))\n",
    "    \n",
    "    \n",
    "    #print([di[0] for di in ds.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-field",
   "metadata": {},
   "source": [
    "### 2. What is in each batch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "continental-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ad80f1588b45beaf86eab68630f8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "ds = load_dataset(\"glue\", \"rte\")\n",
    "dataloader = DataLoader(ds[\"validation\"], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "original-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what is in one batch\n",
    "for b in dataloader:\n",
    "    batch = {k:v for k,v in b.items()}\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "humanitarian-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.',\n",
       "  'Yet, we now are discovering that antibiotics are losing their effectiveness against illness. Disease-causing bacteria are mutating faster than we can come up with new antibiotics to fight the new variations.',\n",
       "  'Cairo is now home to some 15 million people - a burgeoning population that produces approximately 10,000 tonnes of rubbish per day, putting an enormous strain on public services. In the past 10 years, the government has tried hard to encourage private investment in the refuse sector, but some estimate 4,000 tonnes of waste is left behind every day, festering in the heat as it waits for someone to clear it up. It is often the people in the poorest neighbourhoods that are worst affected. But in some areas they are fighting back. In Shubra, one of the northern districts of the city, the residents have taken to the streets armed with dustpans and brushes to clean up public areas which have been used as public dumps.',\n",
       "  'The Amish community in Pennsylvania, which numbers about 55,000, lives an agrarian lifestyle, shunning technological advances like electricity and automobiles. And many say their insular lifestyle gives them a sense that they are protected from the violence of American society. But as residents gathered near the school, some wearing traditional garb and arriving in horse-drawn buggies, they said that sense of safety had been shattered. \"If someone snaps and wants to do something stupid, there\\'s no distance that\\'s going to stop them,\" said Jake King, 56, an Amish lantern maker who knew several families whose children had been shot.'],\n",
       " 'sentence2': ['Christopher Reeve had an accident.',\n",
       "  'Bacteria is winning the war against antibiotics.',\n",
       "  '15 million tonnes of rubbish are produced daily in Cairo.',\n",
       "  'Pennsylvania has the biggest Amish community in the U.S.'],\n",
       " 'label': tensor([1, 0, 1, 1]),\n",
       " 'idx': tensor([0, 1, 2, 3])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-eclipse",
   "metadata": {},
   "source": [
    "### 3. How to prepare a batch for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "billion-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "drawn-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/zhuzi/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44d3e74baa841ae8f1aa81987f0cedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/zhuzi/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d69bdac2f554e82a.arrow\n",
      "Loading cached processed dataset at /Users/zhuzi/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d74cc9f2f2fee5c1.arrow\n",
      "Loading cached processed dataset at /Users/zhuzi/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8e383f62e6c35df8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "odict_keys(['loss', 'logits'])\n"
     ]
    }
   ],
   "source": [
    "# What happens in the tokenize function (that is `map`ped to the dataset)?\n",
    "def tokenize_function(examples):\n",
    "    processed_examples = []\n",
    "    for s1, s2 in zip(examples[\"sentence1\"], examples[\"sentence2\"]):\n",
    "        processed_examples.append(s1 + tokenizer.sep_token + s2)\n",
    "    return tokenizer(processed_examples, padding=\"max_length\", truncation=True)\n",
    "    \n",
    "raw_ds = load_dataset(\"glue\", \"rte\")\n",
    "ds = raw_ds.map(tokenize_function, batched=True).rename_column(\"label\", \"labels\")\n",
    "dataloader = DataLoader(ds[\"train\"], batch_size=4)\n",
    "for b in dataloader:\n",
    "    batch = {k:v for k,v in b.items()}\n",
    "    outputs = model(\n",
    "        input_ids=torch.stack(batch[\"input_ids\"]).transpose(0, 1), \n",
    "        labels=batch[\"labels\"], \n",
    "        attention_mask=torch.stack(batch[\"attention_mask\"]).transpose(0, 1))\n",
    "    print(outputs.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-integer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-reggae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
