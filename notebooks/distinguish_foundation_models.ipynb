{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "productive-agency",
   "metadata": {},
   "source": [
    "## Distinguish foundation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuous-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weekly-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>rte</th>\n",
       "      <th>cola</th>\n",
       "      <th>qnli</th>\n",
       "      <th>mrpc</th>\n",
       "      <th>sst2</th>\n",
       "      <th>qqp</th>\n",
       "      <th>bigram_shift_layer_0</th>\n",
       "      <th>coordination_inversion_layer_0</th>\n",
       "      <th>obj_number_layer_0</th>\n",
       "      <th>...</th>\n",
       "      <th>subj_number_layer_11</th>\n",
       "      <th>tree_depth_layer_11</th>\n",
       "      <th>bigram_shift_layer_12</th>\n",
       "      <th>coordination_inversion_layer_12</th>\n",
       "      <th>obj_number_layer_12</th>\n",
       "      <th>odd_man_out_layer_12</th>\n",
       "      <th>past_present_layer_12</th>\n",
       "      <th>subj_number_layer_12</th>\n",
       "      <th>tree_depth_layer_12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.283714</td>\n",
       "      <td>0.850667</td>\n",
       "      <td>0.654333</td>\n",
       "      <td>0.787333</td>\n",
       "      <td>0.619667</td>\n",
       "      <td>0.879667</td>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings_roberta_base_corr_500</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.250381</td>\n",
       "      <td>0.685667</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.294857</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings_roberta_base_corr_1000</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721333</td>\n",
       "      <td>0.259905</td>\n",
       "      <td>0.605667</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.297714</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings_roberta_base_corr_2000</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747667</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.560667</td>\n",
       "      <td>0.870333</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.301143</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embeddings_roberta_base_corr_4000</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.559333</td>\n",
       "      <td>0.540667</td>\n",
       "      <td>0.804333</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.810333</td>\n",
       "      <td>0.302667</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  LM     rte    cola    qnli    mrpc    sst2  \\\n",
       "0            embeddings_roberta_base  0.7726  0.8437  0.9251  0.8995  0.9438   \n",
       "1   embeddings_roberta_base_corr_500  0.7148  0.8322  0.9213  0.8750  0.9415   \n",
       "2  embeddings_roberta_base_corr_1000  0.7040  0.8380  0.9213  0.8824  0.9392   \n",
       "3  embeddings_roberta_base_corr_2000  0.6859  0.8341  0.9185  0.8824  0.9415   \n",
       "4  embeddings_roberta_base_corr_4000  0.5848  0.8399  0.9209  0.8873  0.9450   \n",
       "\n",
       "      qqp  bigram_shift_layer_0  coordination_inversion_layer_0  \\\n",
       "0  0.9143                   0.5                             0.5   \n",
       "1  0.9164                   0.5                             0.5   \n",
       "2  0.9160                   0.5                             0.5   \n",
       "3  0.9166                   0.5                             0.5   \n",
       "4  0.9165                   0.5                             0.5   \n",
       "\n",
       "   obj_number_layer_0  ...  subj_number_layer_11  tree_depth_layer_11  \\\n",
       "0                 0.5  ...              0.793333             0.283714   \n",
       "1                 0.5  ...              0.704333             0.250381   \n",
       "2                 0.5  ...              0.721333             0.259905   \n",
       "3                 0.5  ...              0.747667             0.276190   \n",
       "4                 0.5  ...              0.785667             0.284190   \n",
       "\n",
       "   bigram_shift_layer_12  coordination_inversion_layer_12  \\\n",
       "0               0.850667                         0.654333   \n",
       "1               0.685667                         0.546667   \n",
       "2               0.605667                         0.547000   \n",
       "3               0.579000                         0.539333   \n",
       "4               0.559333                         0.540667   \n",
       "\n",
       "   obj_number_layer_12  odd_man_out_layer_12  past_present_layer_12  \\\n",
       "0             0.787333              0.619667               0.879667   \n",
       "1             0.813000              0.582667               0.868000   \n",
       "2             0.810000              0.564333               0.864333   \n",
       "3             0.810000              0.560667               0.870333   \n",
       "4             0.804333              0.570667               0.865333   \n",
       "\n",
       "   subj_number_layer_12  tree_depth_layer_12    label  \n",
       "0              0.815333             0.295238  roberta  \n",
       "1              0.806000             0.294857  roberta  \n",
       "2              0.814667             0.297714  roberta  \n",
       "3              0.812000             0.301143  roberta  \n",
       "4              0.810333             0.302667  roberta  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../reports/task1_predict_task_performance.csv\")\n",
    "df[\"label\"] = [\"roberta\"]*6 + [\"xlm\"]*6 + [\"albert\"]*6 + [\"deberta\"]*6 + [\"xlnet\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "applied-rally",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: mean 0.4700 std 0.1631; dev acc: mean 0.0800 std 0.0980\n",
      "Control setting: dev acc: mean 0.0000 std 0.0000\n",
      "Dev acc improvement: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08, 0.09797958971132713, 0.08)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distinguish_models_cv(df_, features, verbose=False):\n",
    "    np.random.seed(42)\n",
    "    df = df_[features + [\"label\"]]\n",
    "    ctrl_features = np.random.normal(0, 0.1, size=(len(df), len(features)))\n",
    "    ctrl_df = pd.DataFrame({\n",
    "        features[j]: ctrl_features[:,j] for j in range(len(features))\n",
    "    })\n",
    "    ctrl_df[\"label\"] = df_[\"label\"]\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    trainaccs, devaccs = [], []\n",
    "    ctrl_trainaccs, ctrl_devaccs = [], []\n",
    "    for train_idx, val_idx in kfold.split(df):\n",
    "        df_tr = df.loc[train_idx]\n",
    "        df_val = df.loc[val_idx]\n",
    "        # Model\n",
    "        model = LogisticRegression()\n",
    "        model.fit(df_tr[features], df_tr[\"label\"])\n",
    "        preds = model.predict(df_tr[features])\n",
    "        trainaccs.append(accuracy_score(df_tr[\"label\"], preds))\n",
    "        preds = model.predict(df_val[features])\n",
    "        devacc = accuracy_score(df_val[\"label\"], preds)\n",
    "        devaccs.append(devacc)\n",
    "\n",
    "        # Control\n",
    "        df_tr = ctrl_df.loc[train_idx]\n",
    "        df_val = ctrl_df.loc[val_idx]\n",
    "        model = LogisticRegression()\n",
    "        model.fit(df_tr[features], df_tr[\"label\"])\n",
    "        preds = model.predict(df_tr[features])\n",
    "        ctrl_trainaccs.append(accuracy_score(df_tr[\"label\"], preds))\n",
    "        preds = model.predict(df_val[features])\n",
    "        ctrl_devacc = accuracy_score(df_val[\"label\"], preds)\n",
    "        ctrl_devaccs.append(ctrl_devacc)\n",
    "\n",
    "    ctrl_devacc_mean = np.mean(ctrl_devaccs)\n",
    "    devacc_mean = np.mean(devaccs)\n",
    "    improvement = devacc_mean - ctrl_devacc_mean\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Train acc: mean {:.4f} std {:.4f}; dev acc: mean {:.4f} std {:.4f}\".format(\n",
    "            np.mean(trainaccs), np.std(trainaccs), np.mean(devaccs), np.std(devaccs)\n",
    "        ))\n",
    "        print(\"Control setting: dev acc: mean {:.4f} std {:.4f}\".format(\n",
    "            np.mean(ctrl_devaccs), np.std(ctrl_devaccs)\n",
    "        ))\n",
    "        print(\"Dev acc improvement: {:.4f}\".format(improvement))\n",
    "    return np.mean(devaccs), np.std(devaccs), improvement\n",
    "    \n",
    "distinguish_models_cv(df, [\n",
    "    \"bigram_shift_layer_5\", \n",
    "    \"coordination_inversion_layer_6\",\n",
    "    \"obj_number_layer_1\",\n",
    "    \"odd_man_out_layer_5\",\n",
    "    \"past_present_layer_1\",\n",
    "    \"subj_number_layer_1\",\n",
    "    \"tree_depth_layer_1\"\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acquired-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [44:14<00:00, 32.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08 ['coordination_inversion_layer_1', 'bigram_shift_layer_2', 'obj_number_layer_12'] 0.08 ['coordination_inversion_layer_1', 'bigram_shift_layer_2', 'obj_number_layer_12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def find_3_best_features(df):\n",
    "    probing_tasks = [\"bigram_shift\", \"coordination_inversion\", \"obj_number\",\n",
    "                    \"odd_man_out\", \"past_present\", \"subj_number\", \"tree_depth\"]\n",
    "    all_features = [f\"{pt}_layer_{layer}\" \n",
    "                    for layer in range(1, 13) \n",
    "                    for pt in probing_tasks]\n",
    "    best_mean_acc = None\n",
    "    best_feats = []\n",
    "    max_improvement = None\n",
    "    max_improvement_feats = []\n",
    "    \n",
    "    all_improvements = []\n",
    "    for i in tqdm(range(len(all_features)-2)):\n",
    "        for j in range(i+1, len(all_features)-1):\n",
    "            for k in range(j+1, len(all_features)):\n",
    "                feats = [all_features[i], all_features[j], all_features[k]]\n",
    "                mean_acc, _, improvement = distinguish_models_cv(df, feats, verbose=False)\n",
    "                \n",
    "                if best_mean_acc is None or mean_acc > best_mean_acc:\n",
    "                    best_mean_acc = mean_acc\n",
    "                    best_feats = feats\n",
    "                if max_improvement is None or improvement > max_improvement:\n",
    "                    max_improvement = improvement\n",
    "                    max_improvement_feats = feats\n",
    "                all_improvements.append(improvement)\n",
    "    return best_mean_acc, best_feats, max_improvement, max_improvement_feats, all_improvements\n",
    "\n",
    "best_mean_acc, best_feats, max_improvement, max_improvement_feats, all_improvements = find_3_best_features(df)\n",
    "print(best_mean_acc, best_feats, max_improvement, max_improvement_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "induced-wallet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002748835061500357, 0.010903529715299653, 0.08)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_improvements), np.std(all_improvements), np.max(all_improvements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08c311d3-38db-4336-99ac-3631c654886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=77.81965146882206, pvalue=0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "ttest_1samp(all_improvements, popmean=0, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1afa0b88-2f23-438f-b8af-028cae2af8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24000000000000005, 0.14966629547095767)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the accuracy of a trivial classifier that always output \"roberta\"?\n",
    "def test_trivial_classifier():\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    accs = []\n",
    "    for train_idx, val_idx in kfold.split(df):\n",
    "        df_val = df.loc[val_idx]\n",
    "        labels = df_val[\"label\"]\n",
    "        trivial_preds = [\"roberta\"] * len(labels)\n",
    "        accs.append(accuracy_score(labels, trivial_preds))\n",
    "    return np.mean(accs), np.std(accs)\n",
    "\n",
    "test_trivial_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6ddb7-4ce3-46a8-8f76-b76688e89a3f",
   "metadata": {},
   "source": [
    "The trivial classifier has expected accuracy that is much higher than the max accuracy (0.08), showing that the probing features can't really distinguish the originating foundation models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
