{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italic-portugal",
   "metadata": {},
   "source": [
    "## Distinguish foundation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hundred-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-cedar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LM</th>\n",
       "      <th>rte</th>\n",
       "      <th>cola</th>\n",
       "      <th>qnli</th>\n",
       "      <th>mrpc</th>\n",
       "      <th>sst2</th>\n",
       "      <th>qqp</th>\n",
       "      <th>bigram_shift_layer_0</th>\n",
       "      <th>coordination_inversion_layer_0</th>\n",
       "      <th>obj_number_layer_0</th>\n",
       "      <th>...</th>\n",
       "      <th>subj_number_layer_11</th>\n",
       "      <th>tree_depth_layer_11</th>\n",
       "      <th>bigram_shift_layer_12</th>\n",
       "      <th>coordination_inversion_layer_12</th>\n",
       "      <th>obj_number_layer_12</th>\n",
       "      <th>odd_man_out_layer_12</th>\n",
       "      <th>past_present_layer_12</th>\n",
       "      <th>subj_number_layer_12</th>\n",
       "      <th>tree_depth_layer_12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings_roberta_base</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.283714</td>\n",
       "      <td>0.850667</td>\n",
       "      <td>0.654333</td>\n",
       "      <td>0.787333</td>\n",
       "      <td>0.619667</td>\n",
       "      <td>0.879667</td>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings_roberta_base_corr_500</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.250381</td>\n",
       "      <td>0.685667</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.294857</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings_roberta_base_corr_1000</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721333</td>\n",
       "      <td>0.259905</td>\n",
       "      <td>0.605667</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.297714</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings_roberta_base_corr_2000</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747667</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.560667</td>\n",
       "      <td>0.870333</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.301143</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embeddings_roberta_base_corr_4000</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785667</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.559333</td>\n",
       "      <td>0.540667</td>\n",
       "      <td>0.804333</td>\n",
       "      <td>0.570667</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>0.810333</td>\n",
       "      <td>0.302667</td>\n",
       "      <td>roberta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  LM     rte    cola    qnli    mrpc    sst2  \\\n",
       "0            embeddings_roberta_base  0.7726  0.8437  0.9251  0.8995  0.9438   \n",
       "1   embeddings_roberta_base_corr_500  0.7148  0.8322  0.9213  0.8750  0.9415   \n",
       "2  embeddings_roberta_base_corr_1000  0.7040  0.8380  0.9213  0.8824  0.9392   \n",
       "3  embeddings_roberta_base_corr_2000  0.6859  0.8341  0.9185  0.8824  0.9415   \n",
       "4  embeddings_roberta_base_corr_4000  0.5848  0.8399  0.9209  0.8873  0.9450   \n",
       "\n",
       "      qqp  bigram_shift_layer_0  coordination_inversion_layer_0  \\\n",
       "0  0.9143                   0.5                             0.5   \n",
       "1  0.9164                   0.5                             0.5   \n",
       "2  0.9160                   0.5                             0.5   \n",
       "3  0.9166                   0.5                             0.5   \n",
       "4  0.9165                   0.5                             0.5   \n",
       "\n",
       "   obj_number_layer_0  ...  subj_number_layer_11  tree_depth_layer_11  \\\n",
       "0                 0.5  ...              0.793333             0.283714   \n",
       "1                 0.5  ...              0.704333             0.250381   \n",
       "2                 0.5  ...              0.721333             0.259905   \n",
       "3                 0.5  ...              0.747667             0.276190   \n",
       "4                 0.5  ...              0.785667             0.284190   \n",
       "\n",
       "   bigram_shift_layer_12  coordination_inversion_layer_12  \\\n",
       "0               0.850667                         0.654333   \n",
       "1               0.685667                         0.546667   \n",
       "2               0.605667                         0.547000   \n",
       "3               0.579000                         0.539333   \n",
       "4               0.559333                         0.540667   \n",
       "\n",
       "   obj_number_layer_12  odd_man_out_layer_12  past_present_layer_12  \\\n",
       "0             0.787333              0.619667               0.879667   \n",
       "1             0.813000              0.582667               0.868000   \n",
       "2             0.810000              0.564333               0.864333   \n",
       "3             0.810000              0.560667               0.870333   \n",
       "4             0.804333              0.570667               0.865333   \n",
       "\n",
       "   subj_number_layer_12  tree_depth_layer_12    label  \n",
       "0              0.815333             0.295238  roberta  \n",
       "1              0.806000             0.294857  roberta  \n",
       "2              0.814667             0.297714  roberta  \n",
       "3              0.812000             0.301143  roberta  \n",
       "4              0.810333             0.302667  roberta  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../reports/task1_predict_task_performance.csv\")\n",
    "df[\"label\"] = [\"roberta\"]*6 + [\"xlm\"]*6 + [\"albert\"]*6 + [\"deberta\"]*6 + [\"xlnet\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "revolutionary-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Acc mean 0.5200, std 0.1122\n",
      "Dev: Acc mean 0.1600, std 0.2332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.16, 0.233238075793812)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distinguish_models_cv(df_, features, verbose=False):\n",
    "    np.random.seed(42)\n",
    "    df = df_[features + [\"label\"]]\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    trainaccs = []\n",
    "    devaccs = []\n",
    "    for train_idx, val_idx in kfold.split(df):\n",
    "        df_tr = df.loc[train_idx]\n",
    "        df_val = df.loc[val_idx]\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(df_tr[features], df_tr[\"label\"])\n",
    "        preds = model.predict(df_tr[features])\n",
    "        trainaccs.append(accuracy_score(df_tr[\"label\"], preds))\n",
    "        preds = model.predict(df_val[features])\n",
    "        devaccs.append(accuracy_score(df_val[\"label\"], preds))\n",
    "    if verbose:\n",
    "        print(\"Train: Acc mean {:.4f}, std {:.4f}\".format(\n",
    "            np.mean(trainaccs), np.std(trainaccs)\n",
    "        ))\n",
    "        print(\"Dev: Acc mean {:.4f}, std {:.4f}\".format(\n",
    "            np.mean(devaccs), np.std(devaccs)\n",
    "        ))\n",
    "    return np.mean(devaccs), np.std(devaccs)\n",
    "    \n",
    "distinguish_models_cv(df, [\n",
    "    \"bigram_shift_layer_5\", \n",
    "    \"coordination_inversion_layer_6\",\n",
    "    \"obj_number_layer_1\",\n",
    "    \"odd_man_out_layer_5\",\n",
    "    \"past_present_layer_1\",\n",
    "    \"subj_number_layer_1\",\n",
    "    \"tree_depth_layer_1\"\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "formed-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [23:18<00:00, 17.05s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27999999999999997,\n",
       " ['bigram_shift_layer_1', 'obj_number_layer_4', 'obj_number_layer_12'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_3_best_features(df):\n",
    "    probing_tasks = [\"bigram_shift\", \"coordination_inversion\", \"obj_number\",\n",
    "                    \"odd_man_out\", \"past_present\", \"subj_number\", \"tree_depth\"]\n",
    "    all_features = [f\"{pt}_layer_{layer}\" \n",
    "                    for layer in range(1, 13) \n",
    "                    for pt in probing_tasks]\n",
    "    best_mean_acc = None\n",
    "    best_feats = []\n",
    "    for i in tqdm(range(len(all_features)-2)):\n",
    "        for j in range(i+1, len(all_features)-1):\n",
    "            for k in range(j+1, len(all_features)):\n",
    "                feats = [all_features[i], all_features[j], all_features[k]]\n",
    "                mean_acc, _ = distinguish_models_cv(df, feats, verbose=False)\n",
    "                if best_mean_acc is None or mean_acc > best_mean_acc:\n",
    "                    best_mean_acc = mean_acc\n",
    "                    best_feats = feats\n",
    "    return best_mean_acc, best_feats\n",
    "\n",
    "find_3_best_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-canvas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
